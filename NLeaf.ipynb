{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager #Automatically manages ChromeDriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ChromeDriver set up with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "url = 'https://www.metacritic.com/game/animal-crossing-new-leaf/user-reviews/'\n",
    "driver.get(url)\n",
    "\n",
    "#Scroll and load dynamic content, allowing it to pause and load after each scroll\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "#Get initial height of the page\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    # Wait to load more content\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    # Calculate new scroll height and compare it with the last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break  # Break the loop if no more new content is loaded (end of page)\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "#Create a dictionary so that all the parsed data can be stored\n",
    "review_dict = {'name':[], 'date':[], 'rating':[], 'review':[]}\n",
    "\n",
    "for review in soup.find_all('div', class_='c-siteReview_main'):\n",
    "    try:\n",
    "        review_dict['name'].append(review.find('a', class_='c-siteReviewHeader_username').text.strip())\n",
    "    except AttributeError:\n",
    "        review_dict['name'].append(None)\n",
    "    try:\n",
    "        review_dict['date'].append(review.find('div', class_='c-siteReviewHeader_reviewDate').text.strip())\n",
    "    except AttributeError:\n",
    "        review_dict['date'].append(None)\n",
    "    try:\n",
    "        review_dict['rating'].append(review.find('div', class_='c-siteReviewHeader_reviewScore').find_all('div')[0].text)\n",
    "    except AttributeError:\n",
    "        review_dict['rating'].append(None)\n",
    "    try:\n",
    "        review_dict['review'].append(review.find('div', class_='c-siteReview_quote').find('span').text)\n",
    "    except AttributeError:\n",
    "        review_dict['review'].append(None)\n",
    "\n",
    "NLReviews = pd.DataFrame(review_dict)\n",
    "\n",
    "NLReviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data frame in a CSV file\n",
    "NLReviews.to_csv('new_leaf_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
